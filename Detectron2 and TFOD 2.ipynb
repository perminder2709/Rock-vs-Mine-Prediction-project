{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755ff18-6004-43d3-90eb-d87b3eb689f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What types of tasks does Detectron2 support?\n",
    "Detectron2 supports a variety of computer vision tasks, including:\n",
    "\n",
    "Object detection\n",
    "\n",
    "Instance segmentation\n",
    "\n",
    "Semantic segmentation\n",
    "\n",
    "Keypoint detection (pose estimation)\n",
    "\n",
    "Panoptic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066214a3-eb7b-4a0b-9709-d9b4206bb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why is data annotation important when training object detection models?\n",
    "Data annotation is critical for creating high-quality labeled datasets, which are essential for supervised learning. Properly labeled data ensures:\n",
    "\n",
    "Accurate learning of patterns.\n",
    "\n",
    "Better performance and generalization.\n",
    "\n",
    "Evaluation of model accuracy against ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b2dd5-2656-4728-abbf-326c9c13c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What does batch size refer to in the context of model training?\n",
    "Batch size refers to the number of training samples processed together in one forward and backward pass during training. It impacts:\n",
    "\n",
    "GPU memory usage.\n",
    "\n",
    "Convergence speed.\n",
    "\n",
    "Stability of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce24e0-f823-40dc-997b-5f092af4dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the purpose of pretrained weights in object detection models?\n",
    "Pretrained weights provide a starting point for training by leveraging features learned from large datasets (e.g., ImageNet, COCO). This:\n",
    "\n",
    "Speeds up training.\n",
    "\n",
    "Reduces the need for large datasets.\n",
    "\n",
    "Improves model performance for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d297f-3eee-4228-81be-d23272635e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how can you verify that Detectron2 was installed correctly?\n",
    "You can verify the installation by:\n",
    "\n",
    "Importing Detectron2 in Python without errors: import detectron2.\n",
    "\n",
    "Running a sample script or testing with a demo image.\n",
    "\n",
    "Checking version details with detectron2.__version__.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff573809-054b-4246-85d2-f079ba51bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is TFOD2, and why is it widely used?\n",
    "TFOD2 (TensorFlow Object Detection API v2) is a framework for building object detection models. It's widely used because:\n",
    "\n",
    "It offers a variety of prebuilt models.\n",
    "\n",
    "It supports TensorFlowâ€™s ecosystem.\n",
    "\n",
    "It includes utilities for data preprocessing, evaluation, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3d642-9b3d-4cc4-8e60-f024bd94349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How does learning rate affect model training in Detectron2?\n",
    "The learning rate controls the step size in updating model weights. Effects:\n",
    "\n",
    "Too high: Training may diverge or oscillate.\n",
    "\n",
    "Too low: Slow convergence.\n",
    "\n",
    "Well-tuned: Faster convergence and better model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef9f60-e8e8-440c-87a2-ef819e904c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why might Detectron2 use PyTorch as its backend framework?\n",
    "Detectron2 uses PyTorch because it provides:\n",
    "\n",
    "Dynamic computation graphs.\n",
    "\n",
    "Ease of debugging.\n",
    "\n",
    "Flexibility for model customization.\n",
    "\n",
    "Wide adoption and community support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff8abb-5786-4dde-8a4b-b9a3435c2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What types of pretrained models does TFOD2 support?\n",
    "TFOD2 supports pretrained models like:\n",
    "\n",
    "SSD (Single Shot Detector)\n",
    "\n",
    "Faster R-CNN\n",
    "\n",
    "EfficientDet\n",
    "\n",
    "YOLO (via external support)\n",
    "\n",
    "MobileNet-based models for edge devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59756a95-380d-42d7-baf6-f2864f82a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How can data path errors impact Detectron2?\n",
    "Incorrect data paths can cause:\n",
    "\n",
    "File not found errors.\n",
    "\n",
    "Incorrect dataset loading.\n",
    "\n",
    "Poor model performance due to missing or corrupted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b253054-951f-477b-81d8-0bf31be95d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is Detectron2?\n",
    "Detectron2 is a state-of-the-art object detection and segmentation framework by Facebook AI. It is built on PyTorch and provides modularity, scalability, and support for advanced computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48c049-9e87-4954-b7f3-b020bf65ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are TFRecord files, and why are they used in TFOD2?\n",
    "TFRecord files are TensorFlow's binary data format. They are used because:\n",
    "\n",
    "They are efficient for large datasets.\n",
    "\n",
    "They enable faster I/O operations.\n",
    "\n",
    "They support integration with TensorFlow pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b130477-59e6-4e7d-b33b-f10054d210b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What evaluation metrics are typically used with Detectron2?\n",
    "Common evaluation metrics include:\n",
    "\n",
    "Mean Average Precision (mAP)\n",
    "\n",
    "Precision-Recall curves\n",
    "\n",
    "Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32323c0-59da-46f4-bcd6-9231c5d2c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you perform inference with a trained Detectron2 model?\n",
    "Steps for inference:\n",
    "\n",
    "Load the trained model and weights.\n",
    "\n",
    "Prepare the input image.\n",
    "\n",
    "Use the DefaultPredictor or a custom inference pipeline.\n",
    "\n",
    "Visualize or save the predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ebec2-c30b-4875-8d4f-956279bdcb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What does TFOD2 stand for, and what is it designed for?\n",
    "TFOD2 stands for TensorFlow Object Detection API v2. It is designed for training, evaluating, and deploying object detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e5894-a4fb-44a6-a3a2-0adea7399814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What does fine-tuning pretrained weights involve?\n",
    "Fine-tuning involves:\n",
    "\n",
    "Using pretrained weights as initialization.\n",
    "\n",
    "Training the model on a new dataset with adjusted learning rates.\n",
    "\n",
    "Updating only certain layers to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faeae-8771-4810-bd6d-538ac11a5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How is training started in TFOD2?\n",
    "Training in TFOD2 is started by:\n",
    "\n",
    "Configuring the training pipeline (model, dataset, hyperparameters).\n",
    "\n",
    "Running the model_main_tf2.py script.\n",
    "\n",
    "Monitoring logs for progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1248d19-9cb5-49e0-a4a8-29e6ad638c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What does COCO format represent, and why is it popular in Detectron2?\n",
    "The COCO format is a dataset annotation standard used in computer vision. It includes:\n",
    "\n",
    "Bounding boxes, segmentation masks, and keypoints.\n",
    "\n",
    "Support for diverse tasks.\n",
    "It's popular because it is:\n",
    "\n",
    "Well-documented.\n",
    "\n",
    "Widely adopted in benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af863a-e94a-4650-80dd-e680cc9b6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why is evaluation curve plotting important in Detectron2?\n",
    "Evaluation curves (e.g., precision-recall) help:\n",
    "\n",
    "Visualize model performance.\n",
    "\n",
    "Identify areas for improvement.\n",
    "\n",
    "Compare models or training strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6afc0-4b11-4e2e-8903-26ca3d8722cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you configure data paths in TFOD2?\n",
    "You configure data paths by:\n",
    "\n",
    "Setting correct file paths in the pipeline configuration file.\n",
    "\n",
    "Verifying dataset paths are accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9d3ce-029a-4563-ac63-3081583edb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can you run Detectron2 on a CPU?\n",
    "Yes, but it is significantly slower compared to GPU execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a04c4-bf34-457d-8328-7279f618aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why are label maps used in TFOD2?\n",
    "Label maps map class names to numerical IDs. They are used for:\n",
    "\n",
    "Consistent annotation and evaluation.\n",
    "\n",
    "Linking model predictions to human-readable labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69698d-09d6-406a-9558-1d299aa0562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What makes TFOD2 popular for real-time detection tasks?\n",
    "TFOD2â€™s popularity stems from:\n",
    "\n",
    "Support for lightweight models like SSD and EfficientDet.\n",
    "\n",
    "Integration with TensorFlow Lite for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94e57d-f7c8-40db-93b9-ebf74d6a87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does batch size impact GPU memory usage?\n",
    "Larger batch sizes require more GPU memory, while smaller batch sizes use less memory but may increase training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c329a4-523a-44fd-b63d-ddc18ee2e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whatâ€™s the role of Intersection over Union (IoU) in model evaluation?\n",
    "IoU measures the overlap between predicted and ground truth boxes, determining:\n",
    "\n",
    "Detection accuracy.\n",
    "\n",
    "Contribution to metrics like mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde6da0-663a-44bd-a00b-2a7ddde576e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is Faster R-CNN, and does TFOD2 support it?\n",
    "Faster R-CNN is a two-stage object detection model known for accuracy. TFOD2 supports Faster R-CNN with configurable pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc5fcd-43d9-4708-befd-5ac4a7a3359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How does Detectron2 use pretrained weights?\n",
    "Detectron2 initializes models with pretrained weights, allowing faster convergence and better generalization when fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566612c-9679-4cc2-8e23-dc74155e84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What format is typically used to store training data in TFOD2?\n",
    "TFOD2 typically uses:\n",
    "\n",
    "TFRecord format for training.\n",
    "\n",
    "COCO format is also supported with converters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe289290-6ce6-4e5f-94ef-d2cc506f63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you install Detectron2 using pip and check the version of Detectron2?\n",
    "Installation:\n",
    "\n",
    "pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu117/torch2.0/index.html\n",
    "Check version:\n",
    "\n",
    "import detectron2\n",
    "print(detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ab861-b1a3-43ac-9679-459fa63cb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you perform inference with Detectron2 using an online image?\n",
    "Import necessary libraries:\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "Download the image:\n",
    "\n",
    "url = 'https://example.com/image.jpg'\n",
    "response = requests.get(url)\n",
    "image = cv2.imdecode(np.frombuffer(response.content, np.uint8), cv2.IMREAD_COLOR)\n",
    "Load the model and run inference:\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"path_to_model_config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"path_to_model_weights.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d751f6-eeb6-4721-a177-6e79543921c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you visualize evaluation metrics in Detectron2, such as training loss?\n",
    "Use TensorBoard:\n",
    "\n",
    "tensorboard --logdir output/\n",
    "Alternatively, use the events.out.tfevents file generated during training with libraries like tensorboardX or Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a02231-da44-48dd-adbc-b94c4a68b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you run inference with TFOD2 on an online image?\n",
    "Download the image:\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "url = 'https://example.com/image.jpg'\n",
    "response = requests.get(url, stream=True)\n",
    "image = Image.open(response.raw)\n",
    "Preprocess the image and load the model:\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "image_np = np.array(image)\n",
    "detection_model = tf.saved_model.load(\"path_to_saved_model\")\n",
    "Run inference and visualize:\n",
    "\n",
    "input_tensor = tf.convert_to_tensor([image_np])\n",
    "detections = detection_model(input_tensor)\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0].numpy(),\n",
    "    detections['detection_classes'][0].numpy().astype(int),\n",
    "    detections['detection_scores'][0].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf0638-aca3-4a0b-8229-7bb81e658e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you install TensorFlow Object Detection API in Jupyter Notebook?\n",
    "Clone the repository:\n",
    "\n",
    "git clone https://github.com/tensorflow/models.git\n",
    "cd models/research\n",
    "Install dependencies:\n",
    "\n",
    "pip install -r requirements.txt\n",
    "Compile protos and set paths:\n",
    "\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e33db2-ead7-40ab-b3e2-9ea92e156cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How can you load a pre-trained TensorFlow Object Detection model?\n",
    "Download the model from the TF2 Model Zoo.\n",
    "\n",
    "Load the model:\n",
    "import tensorflow as tf\n",
    "model = tf.saved_model.load(\"path_to_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee13c8d-06eb-4a2f-9f5a-7d987def0f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you preprocess an image from the web for TFOD2 inference?\n",
    "Download the image:\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "response = requests.get('https://example.com/image.jpg')\n",
    "image = Image.open(response.raw)\n",
    "image_np = np.array(image)\n",
    "Convert to TensorFlow format:\n",
    "input_tensor = tf.convert_to_tensor([image_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b744e-9637-40ea-b91e-8525d3c24fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you visualize bounding boxes for detected objects in TFOD2 inference?\n",
    "Use the visualization_utils library:\n",
    "\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0].numpy(),\n",
    "    detections['detection_classes'][0].numpy().astype(int),\n",
    "    detections['detection_scores'][0].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95494fa9-bd6d-44c9-9de8-982b0b554164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you define classes for custom training in TFOD2?\n",
    "Create a label map file, e.g., label_map.pbtxt:\n",
    "item {\n",
    "  id: 1\n",
    "  name: \"class_name\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620737a-d742-4aff-b7e0-f6fd65c71482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do you resize an image before detecting objects?\n",
    "Use OpenCV:\n",
    "\n",
    "import cv2\n",
    "resized_image = cv2.resize(image, (width, height))\n",
    "Alternatively, use PIL:\n",
    "\n",
    "from PIL import Image\n",
    "resized_image = image.resize((width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93e7bf-c8e7-4b0b-bdd3-9ef54b6c81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How can you apply a color filter (e.g., red filter) to an image?\n",
    "Use OpenCV:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"path_to_image.jpg\")\n",
    "red_filter = np.zeros_like(image)\n",
    "red_filter[:, :, 2] = 255  # Set red channel\n",
    "filtered_image = cv2.addWeighted(image, 0.5, red_filter, 0.5, 0)\n",
    "cv2.imshow(\"Red Filtered Image\", filtered_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
